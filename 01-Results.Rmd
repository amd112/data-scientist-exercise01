# Modeling {-}


```{r initial_models, eval = FALSE}
s = 1:nrow(flat)
train = sample(s, 6000)
validate = sample(s[!s %in% train], 6000)
test = s[(!s %in% train) & (!s %in% validate)]


l = glm(over_50k ~ ., data = flat[train, ], family = binomial(link = "logit"))
p = predict(l, flat)

x = rep(NA, 50)
for (i in 1:50) {
  rf = randomForest(over_50k ~ ., mtry = 7, ntree = 100, data = flat, subset = train)
  x[i] = 1 - ((rf$confusion[1, 1] + rf$confusion[2, 2])/sum(rf$confusion))
}
hist(x)

x = rep(NA, 50)
for (i in 1:50) {
  nb = naiveBayes(x= flat[, c(-14)], y = flat$over_50k, subset = train)
  p = predict(nb, flat[, c(-14)])
  t = table(pred=p,true=flat$over_50k)
  x[i] = 1 - ((t[1, 1] + t[2, 2])/sum(t))
}
hist(x)

```