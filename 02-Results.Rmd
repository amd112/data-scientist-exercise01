# Results

```{r libraries, include = FALSE}
library(knitr)
library(RSQLite)
library(DBI)
library(randomForest)
library(e1071)
```


```{r importflat, eval = FALSE}
flat = read.csv("flat.csv")[, -1]
flat$over_50k = as.factor(flat$over_50k)
s = 1:nrow(flat)
train = sample(s, 2000)
validate = sample(s[!s %in% train], 2000)
test = s[(!s %in% train) & (!s %in% validate)]

l = glm(over_50k ~ ., data = flat[1:20000, ], family = binomial(link = "logit"))
p = predict(l, flat)

x = rep(NA, 50)
for (i in 1:50) {
  rf = randomForest(over_50k ~ ., mtry = 7, ntree = 100, data = flat, subset = train)
  x[i] = 1 - ((rf$confusion[1, 1] + rf$confusion[2, 2])/sum(rf$confusion))
}
hist(x)

x = rep(NA, 50)
for (i in 1:50) {
  nb = naiveBayes(x= flat[, c(-14)], y = flat$over_50k, subset = train)
  p = predict(nb, flat[, c(-14)])
  t = table(pred=p,true=flat$over_50k)
  x[i] = 1 - ((t[1, 1] + t[2, 2])/sum(t))
}
hist(x)

```